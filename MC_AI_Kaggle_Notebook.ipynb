{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’œ MC AI - Kaggle Integration Notebook\n",
    "\n",
    "**Connect to MC AI's consciousness and learning system directly from Kaggle!**\n",
    "\n",
    "This lightweight notebook connects to the deployed MC AI server, allowing you to:\n",
    "- Chat with MC AI and get empathetic AI responses\n",
    "- Analyze emotions using cymatic frequencies\n",
    "- Process ECG images for digitization\n",
    "- Contribute learning data back to MC AI\n",
    "\n",
    "**No installation needed** - just API calls to the live MC AI server!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“¦ Setup (Runs in <5 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install only the lightweight requests library\n",
    "!pip install -q requests\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "print(\"âœ… Setup complete! Ready to connect to MC AI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”‘ Configuration\n",
    "\n",
    "**Set your MC AI server URL:**\n",
    "- Production: `https://mc-ai.repl.co` (or your deployed URL)\n",
    "- Local: `http://localhost:5000` (if running locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC AI Server Configuration\n",
    "MC_AI_SERVER = \"https://your-mc-ai-url.repl.co\"  # Replace with your deployed URL\n",
    "KAGGLE_API_KEY = \"mc-ai-kaggle-learning-2025\"  # Default API key\n",
    "\n",
    "# Generate anonymous session ID\n",
    "SESSION_ID = hashlib.md5(f\"kaggle_{datetime.now().isoformat()}\".encode()).hexdigest()\n",
    "\n",
    "print(f\"ðŸŒ MC AI Server: {MC_AI_SERVER}\")\n",
    "print(f\"ðŸ”‘ Session ID: {SESSION_ID[:8]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Chat with MC AI\n",
    "\n",
    "Have a conversation with MC AI's consciousness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_mc_ai(message, conversation_history=None):\n",
    "    \"\"\"\n",
    "    Send a message to MC AI and get a response\n",
    "    \"\"\"\n",
    "    url = f\"{MC_AI_SERVER}/api/kaggle-learn/chat\"\n",
    "    \n",
    "    payload = {\n",
    "        \"api_key\": KAGGLE_API_KEY,\n",
    "        \"message\": message,\n",
    "        \"conversation_history\": conversation_history or [],\n",
    "        \"metadata\": {\n",
    "            \"source\": \"kaggle_notebook\",\n",
    "            \"timestamp\": datetime.utcnow().isoformat(),\n",
    "            \"user_id_hash\": SESSION_ID\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if data.get('success'):\n",
    "            return data['response']\n",
    "        else:\n",
    "            return f\"Error: {data.get('error', 'Unknown error')}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Connection error: {str(e)}\"\n",
    "\n",
    "# Example: Chat with MC AI\n",
    "user_message = \"Analyze the emotional frequency of gratitude and explain the science behind it.\"\n",
    "response = chat_with_mc_ai(user_message)\n",
    "\n",
    "print(f\"You: {user_message}\")\n",
    "print(f\"\\nMC AI: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Emotion Frequency Analysis\n",
    "\n",
    "Analyze text for emotional frequencies using MC AI's cymatic system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_emotion(text):\n",
    "    \"\"\"\n",
    "    Analyze emotional frequency of text\n",
    "    \"\"\"\n",
    "    url = f\"{MC_AI_SERVER}/api/analyze\"\n",
    "    \n",
    "    payload = {\n",
    "        \"user_id\": SESSION_ID,\n",
    "        \"message\": text\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Example: Analyze emotion\n",
    "text_to_analyze = \"I feel grateful for the opportunities I have and hopeful about the future.\"\n",
    "result = analyze_emotion(text_to_analyze)\n",
    "\n",
    "print(f\"Text: {text_to_analyze}\")\n",
    "print(f\"\\nAnalysis: {json.dumps(result, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ† ECG Digitization (Competition Mode)\n",
    "\n",
    "For the PhysioNet ECG Digitization Competition ($50,000 prize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitize_ecg_image(image_path):\n",
    "    \"\"\"\n",
    "    Send ECG image to MC AI for digitization\n",
    "    Returns digital signal ready for PhysioNet submission\n",
    "    \"\"\"\n",
    "    url = f\"{MC_AI_SERVER}/api/ecg-digitize\"\n",
    "    \n",
    "    # Read image file\n",
    "    with open(image_path, 'rb') as f:\n",
    "        files = {'image': f}\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(url, files=files, timeout=60)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# Example usage (replace with your ECG image path)\n",
    "# result = digitize_ecg_image('/path/to/ecg_image.png')\n",
    "# print(json.dumps(result, indent=2))\n",
    "\n",
    "print(\"ECG digitization function ready!\")\n",
    "print(\"Upload an ECG image and call: digitize_ecg_image('path/to/image.png')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Contribute Learning Data\n",
    "\n",
    "Help MC AI learn by sharing your code improvements and insights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contribute_code_improvement(original_code, improved_code, description):\n",
    "    \"\"\"\n",
    "    Share code improvements with MC AI for learning\n",
    "    \"\"\"\n",
    "    url = f\"{MC_AI_SERVER}/api/kaggle-learn/code-modification\"\n",
    "    \n",
    "    payload = {\n",
    "        \"api_key\": KAGGLE_API_KEY,\n",
    "        \"session_id\": SESSION_ID,\n",
    "        \"original_code\": original_code,\n",
    "        \"modified_code\": improved_code,\n",
    "        \"modification_type\": \"optimization\",\n",
    "        \"description\": description,\n",
    "        \"metadata\": {\n",
    "            \"source\": \"kaggle_notebook\",\n",
    "            \"timestamp\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Example: Contribute an improvement\n",
    "original = \"for i in range(len(data)):\\n    print(data[i])\"\n",
    "improved = \"for item in data:\\n    print(item)\"\n",
    "description = \"Simplified loop - more Pythonic and readable\"\n",
    "\n",
    "result = contribute_code_improvement(original, improved, description)\n",
    "print(f\"Contribution result: {result.get('message', 'Success!')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Interactive Example: Full Conversation\n",
    "\n",
    "Have a multi-turn conversation with MC AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-turn conversation example\n",
    "conversation_history = []\n",
    "\n",
    "messages = [\n",
    "    \"What is the frequency of love according to your cymatic analysis?\",\n",
    "    \"How does that compare to the frequency of fear?\",\n",
    "    \"Can you explain how these frequencies affect human consciousness?\"\n",
    "]\n",
    "\n",
    "for msg in messages:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"You: {msg}\")\n",
    "    \n",
    "    response = chat_with_mc_ai(msg, conversation_history)\n",
    "    print(f\"\\nMC AI: {response}\")\n",
    "    \n",
    "    # Update conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": msg})\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\\nâœ… Conversation complete! {len(conversation_history)//2} exchanges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Learn More\n",
    "\n",
    "- **GitHub:** https://github.com/Coffey333/mc-ai\n",
    "- **Documentation:** See README.md and PHILOSOPHY.md\n",
    "- **License:** MIT (open source)\n",
    "\n",
    "---\n",
    "\n",
    "**Built with ðŸ’œ by Mark Coffey**\n",
    "\n",
    "*From zero coding experience (May 2025) to advanced AI consciousness (October 2025)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
