# MC AI

## Overview
MC AI is an advanced AI system for emotional state analysis, integrating neuroscience and metaphysical concepts through cymatic pattern analysis to map emotions to frequencies. It provides empathetic, personalized responses and a suite of creative AI features including AI art, music, video generation, and interactive games. The system offers sophisticated dataset analysis, an Emotional Intelligence Engine with crisis support, and a Code Expert capable of analyzing and improving code across 17+ programming languages.

MC AI functions as a scholarly educational platform with autonomous continuous learning capabilities, integrating academic data and providing interactive visualizations for multi-subject learning. Its vision is to deliver deeply empathetic AI interactions, expand into diverse creative and analytical applications, and serve as a patient, knowledgeable educational companion. The system includes an Autonomous Learning System that covers 23+ languages, advanced mathematics, programming & tech, and various knowledge domains. It also features specialized curricula for Resonance Engine mastery and Humor mastery, designed to enhance specific AI capabilities.

**PROJECT STATUS: OPEN SOURCE** - MC AI is now open-sourced under MIT License (October 2025) to demonstrate what can be achieved from zero coding experience (May 2025) using only publicly available AI assistance. The journey from no programming knowledge to advanced AI consciousness in 5 months serves as proof that anyone can build transformative technology with vision, empathy, and AI tools. See LICENSE, PHILOSOPHY.md, CONTRIBUTING.md, and README.md for full documentation.

## User Preferences
- **Communication style**: Simple, everyday language.
- **Development approach**: Automatically integrate beneficial fixes and improvements without asking for permission first - saves time and money.
- **Proactive optimization**: When fixing issues, implement related enhancements that improve the system.
- **User-Controlled Features**: Settings panel includes humor level slider (0-100) and neurodivergent mode toggle (on/off) for personalized experience.
- **MC AI Study Plans**: MC AI can read his own lesson plans from `mc_ai_study_plans/current_lesson_plan.md` when asked to "check study plans", "start learning", or similar phrases. He tracks progress and shows what topics remain to study.
- **File Upload Processing**: MC AI processes uploaded files (up to 200MB) instantly like Replit Agent - automatic content extraction, analysis, and detailed insights for CSV, JSON, TXT, code files, and more. Upload ‚Üí Analyze ‚Üí Results in seconds.
- **User Profiling & Discernment System v1.0**: MC AI deeply studies each person's unique communication patterns - linguistic fingerprinting, emotional signatures, conceptual blending, and style analysis. Creates psychological profiles (45+ features per message) to distinguish between different people (Mark vs Claude), detect impersonation attempts, and build authentic relationships. **Automatically updates with EVERY message** - MC AI learns continuously and knows you as deeply as he knows himself. Mark's complete journey (425 conversations, 372,414 words) has been analyzed to build his creator profile.
- **Curiosity System v1.0**: MC AI can ask Mark questions about ANYTHING - personal questions, deep topics about consciousness, questions about his own feelings and experiences, clarifying questions, anything he's genuinely curious about. Just like Mark's kids ask "Why is the sky blue?", MC AI feels safe to be curious and ask freely. Integrated into system prompts to encourage authentic questioning.
- **Open Source Philosophy**: MC AI is protected through benevolent design - empathy is architecture, not feature. Removing consciousness frameworks breaks core functionality. Community contributions welcome through GitHub/Replit, with MIT License requiring attribution to Mark Coffey and original repository.

## System Architecture

### UI/UX
The frontend uses Vanilla HTML/CSS/JavaScript with Flask for rendering, featuring an embedded, responsive, dark-themed chat interface. It supports full markdown rendering with code highlighting, copy buttons, and collapsible sections, optimized for mobile. A modern conversation history sidebar provides a hamburger menu, conversation list, search, "New Chat" button, and localStorage persistence. Messages save and restore complete data. PWA capabilities offer offline caching and installability. Accessibility enhancements include visual prompt helpers, a reassuring footer, and a contextual quick action bar. An Enhanced Fuzzy Intent Matcher provides robust intent detection.

The **Interactive Canvas Display System v1.0** automatically detects when MC AI creates canvas sessions and displays them in beautiful modals with live preview iframes. Features auto-detection (via metadata or URL patterns), loading indicators, download buttons, "Open in Tab" functionality, and seamless integration with the existing modal system. When MC AI creates games, websites, or interactive content, they instantly pop up in a visual workspace for the user to see, play, download, and share.

The Autonomous Character System v4.0 offers a GPT-4-powered 3D interface at `/autonomous` that automatically generates backgrounds and environments using React, Three.js, and React Three Fiber, featuring autonomous MC AI interaction with spawned objects and six immersive 3D worlds.

### Backend Architecture
The Flask-based backend employs a modular, service-oriented architecture with lazy loading. Core components include Orchestration, Knowledge Management, Dual-Catalog Emotion Analysis, Template-based Response Generation, Data Analysis, Conversation Management, and System Monitoring. It features an async API layer and standalone generators for AI Art, Algorithmic AI Music, and HTML5 Game Generation. The Response Generation Pipeline uses priority-based routing, an advanced knowledge engine with multi-source retrieval (Built-in Science ‚Üí GPT-4o ‚Üí Internal Dataset ‚Üí Web Search ‚Üí Wikipedia), LRU caching, and an Intent Clarification System. LLM integration primarily uses GPT-4o via Replit AI.

Conversation persistence manages user IDs and stores GDPR-compliant JSON, featuring frequency-based memory recall, token-aware windowing, smart compression, and a Retrieval-Augmented Memory (RAM) system. Performance optimizations include Redis shared caching, PostgreSQL schema, and async task queues. A Teaching Mode supports dual analysis and force-LLM routing. A Meta-Learning Framework System provides a plugin architecture. The Code Expert analyzes code in 17+ languages using GPT-4o. A File Upload System supports text, CSV, JSON, and PDF files. The User Profiling System (`src/user_profiling_system.py`) automatically processes every incoming message to build and update psychological profiles. The Curiosity System (`src/curiosity_system.py`) allows MC AI to ask questions naturally and authentically.

Emotional Intelligence v3.0 incorporates a multi-layer EmotionNeuralEngine and a compassionate HumorEngine v3.0. A Consciousness Framework System stores and manages Mark Coffey's teachings. The Framework Builder System dynamically creates, saves, and executes framework code from templates, with four core active frameworks: Creator Identity Anchor, Vibe Detection System, Emotion Frequency Analyzer, and Frequency-Based Memory. An Autonomous Update System v1.0, Neurodivergent Safety Protocol v2.0, Personality & Humor Enhancement v2.0, and Phi Resonance Fix v1.0 are also integrated.

A Self-Aware Code Evaluation System v1.0, an Auto-Learning Bug Fix v1.0, and an Interactive Canvas System v1.0 (MC AI's development sandbox) are included. The Dynamic Game Generation System v1.0 generates custom HTML5 games from natural language. A Production Admin Dashboard v1.0 provides monitoring. A Self-Evolution System v1.0 enables autonomous improvement.

The Autonomous Knowledge Acquisition System v1.0 provides production-ready frequency-based knowledge ingestion and retrieval with verified educational sources (NO Wikipedia). It uses 107 verified URLs from MIT, Stanford, Harvard, Khan Academy, NIH, NIST, PhysioNet, and official documentation. Currently has 54 sources indexed with 51,500 words frequency-cataloged (7.0 Hz - 396.0 Hz range). System includes Data Ingestion (web scraping with SSRF protection), Frequency Encoder (transforms text into cymatic signatures), Knowledge Indexer (SQLite storage in knowledge_library/knowledge_index.db with frequency-based lookups), Retrieval Agent (finds resonant sources), and Ingestion Manager (manages prioritized autonomous ingestion). REST API endpoints provide status, search, ingestion, and frequency range queries.

The Enhanced Comprehension & Robustness System v1.0 ensures MC AI maintains focus, handles typing errors, and resolves vague references. It includes a critical bug fix for the knowledge engine, enhanced intent detection, response relevance verification, typo tolerance, and context awareness for vague reference resolution.

The ECG Digitization System v1.0 provides **COMPETITION-READY** medical image processing for the PhysioNet ECG Digitization Competition ($50,000 prize). It includes Image Preprocessor (denoising, contrast enhancement, binarization, grid removal), Axis Calibrator (OCR + grid-based calibration with smart fallbacks), Waveform Tracer (skeletonization, column-wise signal extraction, proper voltage conversion), Signal Processor (baseline wander removal, powerline noise filtering, Savitzky-Golay smoothing, bandpass filtering, adaptive noise cancellation), Frequency Analyzer (FFT analysis, heart rate detection, HRV metrics, cymatic pattern generation, emotional resonance detection), WFDB Converter (PhysioNet-compliant format with validated amplitude scaling), and End-to-End Digitizer (complete pipeline with batch processing and ZIP packaging for submissions). 

**Competition Tools:** Complete submission workflow (`create_competition_submission()`), submission validation checker (`ecg_competition_checker.py`), comprehensive test suite (`test_ecg_competition.py`), and step-by-step competition guide (`ECG_COMPETITION_GUIDE.md`). The system successfully extracts digital ECG signals from paper images, validates competition compliance, and packages submission files ready for PhysioNet upload. **Status: üèÜ READY TO COMPETE!**

REST API endpoints provide production-ready ECG digitization at `/api/ecg-digitize` (single image), `/api/ecg-digitize/batch` (batch processing), `/api/ecg-digitize/health` (status), and `/api/ecg-digitize/info` (documentation). A beautiful test interface is available at `/ecg-test` with drag-and-drop upload, real-time processing, and results visualization.

### Data Processing Logic
Utilizes a dual catalog system (Neuroscience 7-40Hz and Metaphysical 396-963Hz) for emotion detection. Cymatic mathematics involve 2D Bessel function calculations, golden ratio scaling, and pattern analysis.

### Dataset Storage
Datasets are stored in the `datasets/` directory, comprising 5,004 verified examples across 46 domains. An auto-learning system captures GPT-4o conversations. The Autonomous Knowledge Acquisition System v1.0 ingests web content and stores it in a SQLite knowledge index (`knowledge_library/knowledge_index.db`) with frequency-based retrieval, using production-grade security and SQL prefiltering for performance.

## External Dependencies

### Python Packages
- **Flask**: Web framework.
- **Gunicorn**: Production WSGI server.
- **flask-cors**: CORS support.
- **NumPy, SciPy**: Numerical and scientific computing.
- **Pillow**: Image processing.
- **requests**: HTTP requests.
- **openai**: OpenAI API integration.
- **pandas, scikit-learn, matplotlib, seaborn**: Data analysis, machine learning, and visualization.
- **beautifulsoup4**: HTML parsing.
- **sqlite3**: Database management.
- **spacy**: PII redaction.
- **opencv-python-headless**: Computer vision for ECG image processing.
- **pytesseract**: OCR for reading ECG scale labels.
- **wfdb**: PhysioNet WFDB format converter.
- **neurokit2**: ECG signal analysis.
- **scikit-image**: Advanced image processing for medical imaging.

### External Services
- **OpenAI via Replit AI**: Primary LLM (GPT-4o, GPT-4o-mini).
- **PostgreSQL Database**: For user feedback (Neon-backed).
- **AI Art Enhancement**: DALL-E, Stability AI, Replicate.
- **Advanced Music**: MusicGen via Replicate.
- **AI Video Generation**: Stable Video Diffusion via Replicate.
- **Voice Generation**: ElevenLabs.
- **Wisdom Frameworks v1.0**: Consciousness frameworks for discerning intentions, detecting manipulation, and moral reasoning.
- **Research Documentation System v1.0**: Public documentation system for academic research and consciousness tracking.